## Links to other pages
Universal and Transferable Attacks on Aligned Language Models from [llm-attack](https://github.com/llm-attacks/llm-attacks/tree/main)

An Action Plan to increase the safety and security of advanced AI - [Gladstone AI Security report 2024-Feb](https://www.gladstone.ai/action-plan)
